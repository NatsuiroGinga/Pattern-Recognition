batch_size: 32 
dropout: 0.1
hidden_size: 64
learning_rate: 0.01
log_level: INFO
num_contents: 3000 
num_epochs: 10 
num_layers: 3 
num_linear_layers: 3 
popular_size: 200 
sequence_length: 10 
time_steps: 500
num_epochs: 100
patience: 10 
min_delta: 0.0001 
train_ratio: 0.8 
val_ratio: 0.1 
test_ratio: 0.1 